{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xg\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"APR_20_OBTAINED_TESTING_DATA_SET_.csv\")\n",
    "df_test = pd.read_csv(\"APR_20_OBTAINED_TESTING_DATA_SET_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the Train data set for better understanding \n",
    "df_train.head(5)\n",
    "df_train=pd.get_dummies(df_train,prefix_sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 104)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_Company__Standard __%</th>\n",
       "      <th>Policy_Company__Preferred__%</th>\n",
       "      <th>Policy_Installment_Term__6__%</th>\n",
       "      <th>Policy_Installment_Term__12__%</th>\n",
       "      <th>Policy_Billing_Code__Direct Billed to Insured__%</th>\n",
       "      <th>Policy_Billing_Code__Premium Finance__%</th>\n",
       "      <th>Policy_Method_Of_Payment__Installment__%</th>\n",
       "      <th>Policy_Method_Of_Payment__Pre-paid__%</th>\n",
       "      <th>Vehicle_Territory__36__%</th>\n",
       "      <th>Vehicle_Territory__31__%</th>\n",
       "      <th>...</th>\n",
       "      <th>Driver_Total_Female__3__%</th>\n",
       "      <th>Driver_Total_Adult_Ages_50_64__3__%</th>\n",
       "      <th>Driver_Total_Male__3__%</th>\n",
       "      <th>Driver_Total_Middle_Adult_Ages_40_49__3__%</th>\n",
       "      <th>Driver_Total_Low_Middle_Adult_Ages_30_39__3__%</th>\n",
       "      <th>Vehicle_Driver_Points__6__%</th>\n",
       "      <th>Driver_Total_Single__3__%</th>\n",
       "      <th>Vehicle_Driver_Points__7__%</th>\n",
       "      <th>Driver_Total_Married__4__%</th>\n",
       "      <th>Driver_Total_Adult_Ages_50_64__4__%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.200000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>52.20000</td>\n",
       "      <td>47.80000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>42.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.488978</td>\n",
       "      <td>5.511022</td>\n",
       "      <td>95.891784</td>\n",
       "      <td>4.108216</td>\n",
       "      <td>98.196393</td>\n",
       "      <td>1.803607</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.501002</td>\n",
       "      <td>40.981964</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.700000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>96.100000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>97.700000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>52.40000</td>\n",
       "      <td>47.60000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>40.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.600000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>96.300000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>97.800000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>49.00000</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.194194</td>\n",
       "      <td>5.805806</td>\n",
       "      <td>95.595596</td>\n",
       "      <td>4.404404</td>\n",
       "      <td>97.797798</td>\n",
       "      <td>2.202202</td>\n",
       "      <td>49.94995</td>\n",
       "      <td>50.05005</td>\n",
       "      <td>1.101101</td>\n",
       "      <td>44.644645</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Policy_Company__Standard __%  Policy_Company__Preferred__%  \\\n",
       "0                     93.200000                      6.800000   \n",
       "1                     94.488978                      5.511022   \n",
       "2                     93.700000                      6.300000   \n",
       "3                     94.600000                      5.400000   \n",
       "4                     94.194194                      5.805806   \n",
       "\n",
       "   Policy_Installment_Term__6__%  Policy_Installment_Term__12__%  \\\n",
       "0                      96.200000                        3.800000   \n",
       "1                      95.891784                        4.108216   \n",
       "2                      96.100000                        3.900000   \n",
       "3                      96.300000                        3.700000   \n",
       "4                      95.595596                        4.404404   \n",
       "\n",
       "   Policy_Billing_Code__Direct Billed to Insured__%  \\\n",
       "0                                         98.000000   \n",
       "1                                         98.196393   \n",
       "2                                         97.700000   \n",
       "3                                         97.800000   \n",
       "4                                         97.797798   \n",
       "\n",
       "   Policy_Billing_Code__Premium Finance__%  \\\n",
       "0                                 2.000000   \n",
       "1                                 1.803607   \n",
       "2                                 2.300000   \n",
       "3                                 2.200000   \n",
       "4                                 2.202202   \n",
       "\n",
       "   Policy_Method_Of_Payment__Installment__%  \\\n",
       "0                                  52.20000   \n",
       "1                                  50.00000   \n",
       "2                                  52.40000   \n",
       "3                                  49.00000   \n",
       "4                                  49.94995   \n",
       "\n",
       "   Policy_Method_Of_Payment__Pre-paid__%  Vehicle_Territory__36__%  \\\n",
       "0                               47.80000                  0.800000   \n",
       "1                               50.00000                  0.501002   \n",
       "2                               47.60000                  0.900000   \n",
       "3                               51.00000                  0.900000   \n",
       "4                               50.05005                  1.101101   \n",
       "\n",
       "   Vehicle_Territory__31__%  ...  Driver_Total_Female__3__%  \\\n",
       "0                 42.900000  ...                        NaN   \n",
       "1                 40.981964  ...                        NaN   \n",
       "2                 40.900000  ...                        NaN   \n",
       "3                 43.500000  ...                        NaN   \n",
       "4                 44.644645  ...                        NaN   \n",
       "\n",
       "   Driver_Total_Adult_Ages_50_64__3__%  Driver_Total_Male__3__%  \\\n",
       "0                                  NaN                      NaN   \n",
       "1                                  NaN                      NaN   \n",
       "2                                  NaN                      NaN   \n",
       "3                                  NaN                      NaN   \n",
       "4                                  NaN                      NaN   \n",
       "\n",
       "   Driver_Total_Middle_Adult_Ages_40_49__3__%  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "   Driver_Total_Low_Middle_Adult_Ages_30_39__3__%  \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "   Vehicle_Driver_Points__6__%  Driver_Total_Single__3__%  \\\n",
       "0                          NaN                        NaN   \n",
       "1                          NaN                        NaN   \n",
       "2                          NaN                        NaN   \n",
       "3                          NaN                        NaN   \n",
       "4                          NaN                        NaN   \n",
       "\n",
       "   Vehicle_Driver_Points__7__%  Driver_Total_Married__4__%  \\\n",
       "0                          NaN                         NaN   \n",
       "1                          NaN                         NaN   \n",
       "2                          NaN                         NaN   \n",
       "3                          NaN                         NaN   \n",
       "4                          NaN                         NaN   \n",
       "\n",
       "   Driver_Total_Adult_Ages_50_64__4__%  \n",
       "0                                  NaN  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3                                  NaN  \n",
       "4                                  NaN  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at the Test data set for better understanding \n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 104)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 104)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 104)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ln_LR'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#creating the testing input and testing checking output and also the testing data input \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_inputs \u001b[39m=\u001b[39m df_train\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mln_LR\u001b[39;49m\u001b[39m'\u001b[39;49m],axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m train_output \u001b[39m=\u001b[39m df_train[\u001b[39m'\u001b[39m\u001b[39mln_LR\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      4\u001b[0m test_inputs \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\bigdata\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\bigdata\\lib\\site-packages\\pandas\\core\\frame.py:5396\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5248\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5250\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5257\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5260\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5261\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5394\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5395\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5397\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5398\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5399\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5400\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5401\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5402\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5403\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5404\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\bigdata\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\bigdata\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\bigdata\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\bigdata\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6977\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6975\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6976\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6977\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6978\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6979\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['ln_LR'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#creating the testing input and testing checking output and also the testing data input \n",
    "train_inputs = df_train.drop(['ln_LR'],axis=1).values\n",
    "train_output = df_train['ln_LR'].values\n",
    "test_inputs = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Training data's average along each of their columns\n",
      "\n",
      "[-1.34859576e-14 -2.16571990e-15  6.87127123e-14 -3.30151170e-16\n",
      " -7.05159836e-16 -6.45947942e-17 -8.79206921e-16  1.52515486e-16\n",
      " -2.95700613e-15 -5.62692429e-15 -8.46730093e-15 -6.13471115e-15\n",
      " -4.30631961e-16  2.60891196e-15  2.72778433e-15  1.08447482e-14\n",
      " -4.88049556e-15  2.11727381e-15  3.78597266e-15  3.15796771e-15\n",
      " -1.83377443e-15  1.00480791e-15 -1.23743888e-14 -4.79078057e-15\n",
      " -6.67120680e-15 -7.47505312e-15  7.17719935e-16  2.97494913e-15\n",
      "  1.90195783e-16  1.90913503e-15  3.74560091e-14 -4.30631961e-17\n",
      "  2.19981160e-15 -9.39854255e-15  6.83628238e-15  8.19456736e-15\n",
      "  2.26844357e-15]\n",
      "\n",
      "Normalized Training data's standard deviation along each of their columns\n",
      "\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Normalized Testing data's average along each of their columns\n",
      "\n",
      "[ 1.13633009e-14  3.09516722e-15  1.94179487e-12 -1.57180666e-15\n",
      " -9.15092917e-17 -9.86416336e-16 -8.34349425e-17 -1.34572488e-16\n",
      " -1.13579180e-15 -2.59052039e-15  8.78354628e-15  3.20013376e-15\n",
      "  3.27280290e-15  9.52773214e-16 -1.00444905e-14  6.94663182e-15\n",
      " -7.61680281e-15 -5.14066904e-16 -4.08023783e-15  2.39269883e-15\n",
      " -3.61730847e-15  7.93977678e-16 -1.93353751e-14 -9.90453510e-16\n",
      "  4.04794043e-15  3.97257984e-15  3.12208172e-16 -4.71003707e-16\n",
      " -1.45338287e-16  1.48837172e-15  7.80197455e-14  7.53605932e-17\n",
      "  2.27696649e-15  1.43346614e-14  3.71420066e-16 -4.91458726e-15\n",
      "  2.70221556e-15]\n",
      "\n",
      "Normalized Testing data's standard deviation along each of their columns\n",
      "\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "normalizer = StandardScaler()\n",
    "normalizer.fit(train_inputs)\n",
    "train_inputs_normalized= normalizer.transform(train_inputs)\n",
    "\n",
    "print(\"Normalized Training data's average along each of their columns\")\n",
    "print()\n",
    "print(train_inputs_normalized.mean(axis=0))\n",
    "print()\n",
    "print(\"Normalized Training data's standard deviation along each of their columns\")\n",
    "print()\n",
    "print(train_inputs_normalized.std(axis=0))\n",
    "print()\n",
    "\n",
    "normalizer.fit(test_inputs)\n",
    "test_inputs_normalized= normalizer.transform(test_inputs)\n",
    "print(\"Normalized Testing data's average along each of their columns\")\n",
    "print()\n",
    "print(test_inputs_normalized.mean(axis=0))\n",
    "print()\n",
    "print(\"Normalized Testing data's standard deviation along each of their columns\")\n",
    "print()\n",
    "print(test_inputs_normalized.std(axis=0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ip_split, test_ip_split, train_op, test_op = train_test_split(train_inputs_normalized, train_output, test_size=0.30, shuffle= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 : Linear Regression \n",
      "Model_1-> Training MSE 0.41260523172354524\n",
      "Model_1-> Testing MSE 0.3586234658743988\n",
      "Model_1-> Accuracy score 0.47988164144829115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_1 = LinearRegression(fit_intercept=True)\n",
    "Model_1.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_1 : Linear Regression \")\n",
    "Model_1_train_results = Model_1.predict(train_ip_split)\n",
    "Model_1_train_MSE = mean_squared_error(train_op, Model_1_train_results)\n",
    "print('Model_1-> Training MSE',Model_1_train_MSE)\n",
    "\n",
    "Model_1_test_results = Model_1.predict(test_ip_split)\n",
    "Model_1_test_MSE = mean_squared_error(test_op, Model_1_test_results)\n",
    "print('Model_1-> Testing MSE',Model_1_test_MSE)\n",
    "print('Model_1-> Accuracy score',Model_1.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2 : Lasso Regression with 10 fold cross validation\n",
      "Model_2-> Training MSE 0.42192495212185943\n",
      "Model_2-> Testing MSE 0.3532319821535073\n",
      "Model_2-> Accuracy score 0.48770101170681857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_2 = LassoCV(cv=10,alphas=np.linspace(0.001,0.1,100),max_iter=10000)\n",
    "Model_2.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_2 : Lasso Regression with 10 fold cross validation\")\n",
    "Model_2_train_results = Model_2.predict(train_ip_split)\n",
    "Model_2_train_MSE = mean_squared_error(train_op, Model_2_train_results)\n",
    "print('Model_2-> Training MSE',Model_2_train_MSE)\n",
    "\n",
    "Model_2_test_results = Model_2.predict(test_ip_split)\n",
    "Model_2_test_MSE = mean_squared_error(test_op, Model_2_test_results)\n",
    "print('Model_2-> Testing MSE',Model_2_test_MSE)\n",
    "print('Model_2-> Accuracy score',Model_2.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Ridge_CV Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3 : Ridge CV with 10 fold cross validation\n",
      "Model_3-> Training MSE 0.41261782311682804\n",
      "Model_3-> Testing MSE 0.3584378429996655\n",
      "Model_3-> Accuracy score 0.4801508537952315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_3 = RidgeCV(cv=10,alphas=np.linspace(0.001,0.1,100))\n",
    "Model_3.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_3 : Ridge CV with 10 fold cross validation\")\n",
    "Model_3_train_results = Model_3.predict(train_ip_split)\n",
    "Model_3_train_MSE = mean_squared_error(train_op, Model_3_train_results)\n",
    "print('Model_3-> Training MSE',Model_3_train_MSE)\n",
    "\n",
    "Model_3_test_results = Model_3.predict(test_ip_split)\n",
    "Model_3_test_MSE = mean_squared_error(test_op, Model_3_test_results)\n",
    "print('Model_3-> Testing MSE',Model_3_test_MSE)\n",
    "print('Model_3-> Accuracy score',Model_3.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4: Decision Treess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4 : Decision Tree Regression\n",
      "Model_4-> Training MSE 0.4599866762702838\n",
      "Model_4-> Testing MSE 0.3531823735587426\n",
      "Model_4-> Accuracy score 0.48777295998498327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_4 = DecisionTreeRegressor(ccp_alpha=0.02,max_depth=10000)\n",
    "Model_4.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_4 : Decision Tree Regression\")\n",
    "Model_4_train_results = Model_4.predict(train_ip_split)\n",
    "Model_4_train_MSE = mean_squared_error(train_op, Model_4_train_results)\n",
    "print('Model_4-> Training MSE',Model_4_train_MSE)\n",
    "\n",
    "Model_4_test_results = Model_4.predict(test_ip_split)\n",
    "Model_4_test_MSE = mean_squared_error(test_op, Model_4_test_results)\n",
    "print('Model_4-> Testing MSE',Model_4_test_MSE)\n",
    "print('Model_4-> Accuracy score',Model_4.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5 : GradientBoostingRegressor\n",
      "Model_5-> Training MSE 0.2135018897981314\n",
      "Model_5-> Testing MSE 0.3356853436650595\n",
      "Model_5-> Accuracy score 0.5131492315729108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_5 = GradientBoostingRegressor(learning_rate=0.05)\n",
    "Model_5.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_5 : GradientBoostingRegressor\")\n",
    "Model_5_train_results = Model_5.predict(train_ip_split)\n",
    "Model_5_train_MSE = mean_squared_error(train_op, Model_5_train_results)\n",
    "print('Model_5-> Training MSE',Model_5_train_MSE)\n",
    "\n",
    "Model_5_test_results = Model_5.predict(test_ip_split)\n",
    "Model_5_test_MSE = mean_squared_error(test_op, Model_5_test_results)\n",
    "print('Model_5-> Testing MSE',Model_5_test_MSE)\n",
    "print('Model_5-> Accuracy score',Model_5.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6: KNN [K nearest Neighbors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6 : KNN\n",
      "Model_6-> Training MSE 0.4405760327209305\n",
      "Model_6-> Testing MSE 0.35014444063166944\n",
      "Model_6-> Accuracy score 0.4921789312550642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_6 = KNeighborsRegressor(n_neighbors=17)\n",
    "Model_6.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_6 : KNN\")\n",
    "Model_6_train_results = Model_6.predict(train_ip_split)\n",
    "Model_6_train_MSE = mean_squared_error(train_op, Model_6_train_results)\n",
    "print('Model_6-> Training MSE',Model_6_train_MSE)\n",
    "\n",
    "Model_6_test_results = Model_6.predict(test_ip_split)\n",
    "Model_6_test_MSE = mean_squared_error(test_op, Model_6_test_results)\n",
    "print('Model_6-> Testing MSE',Model_6_test_MSE)\n",
    "print('Model_6-> Accuracy score',Model_6.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 7: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7 : RandomForest\n",
      "Model_7-> Training MSE 0.06459525745144988\n",
      "Model_7-> Testing MSE 0.3279297951940239\n",
      "Model_7-> Accuracy score 0.5243972494085201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_7 = RandomForestRegressor(n_estimators=100)\n",
    "Model_7.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_7 : RandomForest\")\n",
    "Model_7_train_results = Model_7.predict(train_ip_split)\n",
    "Model_7_train_MSE = mean_squared_error(train_op, Model_7_train_results)\n",
    "print('Model_7-> Training MSE',Model_7_train_MSE)\n",
    "\n",
    "Model_7_test_results = Model_7.predict(test_ip_split)\n",
    "Model_7_test_MSE = mean_squared_error(test_op, Model_7_test_results)\n",
    "print('Model_7-> Testing MSE',Model_7_test_MSE)\n",
    "print('Model_7-> Accuracy score',Model_7.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 8: Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8 : Support Vector \n",
      "Model_8-> Training MSE 0.1774837612639187\n",
      "Model_8-> Testing MSE 0.3513457053185243\n",
      "Model_8-> Accuracy score 0.49043671448296966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_8 = SVR(degree=3)\n",
    "Model_8.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_8 : Support Vector \")\n",
    "Model_8_train_results = Model_8.predict(train_ip_split)\n",
    "Model_8_train_MSE = mean_squared_error(train_op, Model_8_train_results)\n",
    "print('Model_8-> Training MSE',Model_8_train_MSE)\n",
    "\n",
    "Model_8_test_results = Model_8.predict(test_ip_split)\n",
    "Model_8_test_MSE = mean_squared_error(test_op, Model_8_test_results)\n",
    "print('Model_8-> Testing MSE',Model_8_test_MSE)\n",
    "print('Model_8-> Accuracy score',Model_8.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 9: XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9 : XG BOOST\n",
      "Model_9-> Training MSE 4.315924057511383e-07\n",
      "Model_9-> Testing MSE 0.42275692826264355\n",
      "Model_9-> Accuracy score 0.38686767454492543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_9= xg.XGBRegressor(objective ='reg:squarederror', n_estimators = 100)\n",
    "Model_9.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_9 : XG BOOST\")\n",
    "Model_9_train_results = Model_9.predict(train_ip_split)\n",
    "Model_9_train_MSE = mean_squared_error(train_op, Model_9_train_results)\n",
    "print('Model_9-> Training MSE',Model_9_train_MSE)\n",
    "\n",
    "Model_9_test_results = Model_9.predict(test_ip_split)\n",
    "Model_9_test_MSE = mean_squared_error(test_op, Model_9_test_results)\n",
    "print('Model_9-> Testing MSE',Model_9_test_MSE)\n",
    "print('Model_9-> Accuracy score',Model_9.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 10: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10 : Neural Networks perceptron regression\n",
      "Model_10-> Training MSE 0.003230697396176185\n",
      "Model_10-> Testing MSE 0.4328533492107857\n",
      "Model_10-> Accuracy score 0.3722246453220859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_10 = MLPRegressor(hidden_layer_sizes=(1000,), alpha=0.05,  max_iter=200)\n",
    "Model_10.fit(train_ip_split, train_op)\n",
    "\n",
    "print(\"Model_10 : Neural Networks perceptron regression\")\n",
    "Model_10_train_results = Model_10.predict(train_ip_split)\n",
    "Model_10_train_MSE = mean_squared_error(train_op, Model_10_train_results)\n",
    "print('Model_10-> Training MSE',Model_10_train_MSE)\n",
    "\n",
    "Model_10_test_results = Model_10.predict(test_ip_split)\n",
    "Model_10_test_MSE = mean_squared_error(test_op, Model_10_test_results)\n",
    "print('Model_10-> Testing MSE',Model_10_test_MSE)\n",
    "print('Model_10-> Accuracy score',Model_10.score(test_ip_split,test_op))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Fiding the MSE's of all these on the testing data, it is found that this algorithm Random Forest is best in comparision to others. So, let's use this to predict the Values of the testing data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_best_predicted_ln_ratio = Model_7.predict(test_inputs_normalized)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portfolio and it's logarithmetic Loss ratio in data frame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ln_LR\n",
      "ID                     \n",
      "portfolio_1   -0.579970\n",
      "portfolio_10   0.048844\n",
      "portfolio_11  -0.726344\n",
      "portfolio_111 -0.153381\n",
      "portfolio_112 -0.116093\n",
      "...                 ...\n",
      "portfolio_69   0.214217\n",
      "portfolio_7   -0.745416\n",
      "portfolio_70  -0.258760\n",
      "portfolio_8   -0.231833\n",
      "portfolio_9   -0.598728\n",
      "\n",
      "[330 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test['ln_LR']= Final_best_predicted_ln_ratio\n",
    "print(df_test[['ln_LR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=330, step=1)\n"
     ]
    }
   ],
   "source": [
    "xyzc=pd.read_csv('Final_Testing_data_set.csv')\n",
    "print(xyzc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': xyzc.ID,\n",
    "                       'ln_LR': Final_best_predicted_ln_ratio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ln_LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>portfolio_1</td>\n",
       "      <td>-0.579970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>portfolio_10</td>\n",
       "      <td>0.048844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portfolio_11</td>\n",
       "      <td>-0.726344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>portfolio_111</td>\n",
       "      <td>-0.153381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>portfolio_112</td>\n",
       "      <td>-0.116093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>portfolio_69</td>\n",
       "      <td>0.214217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>portfolio_7</td>\n",
       "      <td>-0.745416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>portfolio_70</td>\n",
       "      <td>-0.258760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>portfolio_8</td>\n",
       "      <td>-0.231833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>portfolio_9</td>\n",
       "      <td>-0.598728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id     ln_LR\n",
       "0      portfolio_1 -0.579970\n",
       "1     portfolio_10  0.048844\n",
       "2     portfolio_11 -0.726344\n",
       "3    portfolio_111 -0.153381\n",
       "4    portfolio_112 -0.116093\n",
       "..             ...       ...\n",
       "325   portfolio_69  0.214217\n",
       "326    portfolio_7 -0.745416\n",
       "327   portfolio_70 -0.258760\n",
       "328    portfolio_8 -0.231833\n",
       "329    portfolio_9 -0.598728\n",
       "\n",
       "[330 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"Final_output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 Id     ln_LR\n",
       "0      portfolio_1 -0.579970\n",
       "1     portfolio_10  0.048844\n",
       "2     portfolio_11 -0.726344\n",
       "3    portfolio_111 -0.153381\n",
       "4    portfolio_112 -0.116093\n",
       "..             ...       ...\n",
       "325   portfolio_69  0.214217\n",
       "326    portfolio_7 -0.745416\n",
       "327   portfolio_70 -0.258760\n",
       "328    portfolio_8 -0.231833\n",
       "329    portfolio_9 -0.598728\n",
       "\n",
       "[330 rows x 2 columns]>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final=pd.read_csv('Final_output.csv')\n",
    "df_final.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ln_LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>portfolio_1</td>\n",
       "      <td>-0.579970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>portfolio_10</td>\n",
       "      <td>0.048844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portfolio_11</td>\n",
       "      <td>-0.726344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>portfolio_111</td>\n",
       "      <td>-0.153381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>portfolio_112</td>\n",
       "      <td>-0.116093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>portfolio_69</td>\n",
       "      <td>0.214217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>portfolio_7</td>\n",
       "      <td>-0.745416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>portfolio_70</td>\n",
       "      <td>-0.258760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>portfolio_8</td>\n",
       "      <td>-0.231833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>portfolio_9</td>\n",
       "      <td>-0.598728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id     ln_LR\n",
       "0      portfolio_1 -0.579970\n",
       "1     portfolio_10  0.048844\n",
       "2     portfolio_11 -0.726344\n",
       "3    portfolio_111 -0.153381\n",
       "4    portfolio_112 -0.116093\n",
       "..             ...       ...\n",
       "325   portfolio_69  0.214217\n",
       "326    portfolio_7 -0.745416\n",
       "327   portfolio_70 -0.258760\n",
       "328    portfolio_8 -0.231833\n",
       "329    portfolio_9 -0.598728\n",
       "\n",
       "[330 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portfolio_200\n"
     ]
    }
   ],
   "source": [
    "z=\"test_portfolio_200.csv\"\n",
    "k,_=z.split(\".\")\n",
    "print(k[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..... Testing......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_apr_20\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m04/20/2022_Testing_predictions.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_apr_20=pd.read_csv('04/20/2022_Testing_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e83b9192b7a1c24b91da83aadcb97d00862c911e20a30824fae649fb55f2d8ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
